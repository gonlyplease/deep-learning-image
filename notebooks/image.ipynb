{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\n",
    "https://kushalvyas.github.io/BOV.html\n",
    "http://127.0.0.1:5500/image-feature-extraction.html\n",
    "https://www.geeksforgeeks.org/feature-extraction-in-image-processing-techniques-and-applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main goal of this exercise is to get a feeling and understanding on the importance of representation and extraction of information from complex media content, in this case images. \n",
    "\n",
    "1. Start Simple with Colour Histograms\n",
    "2. Explore Key Point-Based Feature Extraction\n",
    "    - Explore Key Point-Based Feature Extraction: Once you’re comfortable with simple features, try using SIFT for key point detection and descriptor extraction. SIFT is robust to scale and rotation, which makes it ideal for finding distinctive features in images.\n",
    "        - Visual Bag of Words: After extracting SIFT features, apply a bag-of-words approach to cluster these descriptors into visual “words.” This converts a variable number of key points into a fixed-length feature vector suitable for classifiers.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then, try to use deep learning approaches, such as convolutional neural networks (for images) or recurrent neural networks (for text), or other approaches (but likely not just simple MLPs), and see\n",
    "how your performance differs. Try at least two different architectures, they can be (reusing or be based on )existing, well-known ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare not just the overall measures, but perform a detailed comparison and analysis per class (confusion matrix), to identify if the two approaches lead to different types of errors in the different classes, and also try to identify other patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For images, you can base your DL implementation on the tutorial provided by colleagues at the institute, available at https://github.com/tuwien-musicir/DL_Tutorial/blob/master/Car_recognition.ipynb (you can also check the rest of the repository for interesting code; credit to Thomas Lidy (http://www.ifs.tuwien.ac.at/~lidy/)). Mind also that you will find plenty of examples on how to create and train CNNs / RNNs in various frameworks - tensorflow, keras, pytorch, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also perform a detailed comparison of runtime, considering both time for training and testing, including also the feature extraction components.\n",
    "For the datasets you shall work with, pick two text/image datasets, from the list of suggestions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-1359597a978bc4fa.parquet', 'valid': 'data/valid-00000-of-00001-70d52db3c749a935.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/zh-plus/tiny-imagenet/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex3-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
